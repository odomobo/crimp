# 2026-01-05

Here are some random thoughts I want to try to get on paper, because I'll be taking a break from my project for a while, and I want to be able to pick it back up where I left it.


## out of memory
First off, how to handle out of memory errors. The simplest approach would be to simply crash the application, with a stacktrace and a coredump (ideally). This is the default behavior for go and rust (apparently, at least according to claude), so I'd be in good company. Plus, if there was a failed allocation, that's a sign that we might not be able to recover.

Rather, the only practical way to avoid this is: if there's an application with potentially unbound memory usage, which can regulate its memory usage, it can observe how much memory it's using and actively use strategies to prevent using too much.


## SIGTERM/SIGHUP/SIGINT
Don't handle it at a language level. Let users set it at the C level if they want anything other than default behavior. There's no single approach that works universally (like throwing exceptions)


## DLL_EXPORT
Need to have the build script give everything private visibility by default, and only export necessary symbols.


## crimp/native code mixed
Basically every crimp module will be mixed with native code and crimp code. Technically both are unnecessary, but I expect that most libraries will have both, and some applications will only have crimp code.

The build process will be like this: First, the crimp code will be analyzed, and will build a generated header that will be imported by the c code. Then, the native code and the crimp code will build object files. The native code will be controlled by a user-created cmake script, and the crimp code will generate c files, which will get built using a cmake script. Finally, once both object files are there, they will be linked into a dll or exe file.

This whole build process will be orchestrated by cmake (although in the future, most of it will be handled by the crimp build tool ideally).


## exported symbols from crimp to native code
The idea is: instead of maintaining a header file for your C code, you will maintain a "crimp-header" file (need a better name?), which will do 2 things:

1. It will export to a header file that can be used by your c code, including c structs, function names, etc (although it'll be lightweight compared to the full functionality of header files).
2. It will inform the crimp code which c functions can be called and which c structs can be used.

You still have the c problem of double maintenance, but at least it's only in 2 places instead of 3 places: a C header file, a C source file, and a language-specific file.

Maybe someday you'll be able to export your c functions to be used by other modules too. Cause why not, it could be useful!


## crimp export list
There will also be some convenient way of exporting relevant stuff to c. Think of it like "import" statements at the top of a file. You want to only include the things you'll be using.

So, crimp will have an "export" list file, which will specify what to export. In addition, it'll have some rules around how the exported functions will be namespaced. It'll optionally give them short aliases for ease of use.

So, for example, the "export" file might look like:

```
export foo.bar.Type as Type;
from foo.baz export * as baz_*;
export foo.quux;
```

And then, it would create a header file that would look like:

```
typedef struct crimp_foo_bar_Type {...} crimp_foo_bar_Type;
typedef crimp_foo_bar_Type Type;

crimp_Exception* crimp_foo_baz_first(int i);
#define baz_first crimp_foo_baz_first

crimp_Exception* crimp_foo_baz_second(double d);
#define baz_second crimp_foo_baz_second

crimp_Exception* crimp_foo_quux(Type t);
```

This generated header file will be the same header file which contains the native c function and type declarations, as generated from the "crimp-header" file.

Actually, come to think of it, it may make sense for this to reside in the same file as the "crimp-header" file. Maybe it could be called the "interface" file, something like that. Since it defines the interface that both languages use to talk to each other.


## calloc
Use calloc everywhere...


## function/method overloading
Nope, don't allow it. Period. If it does something different, or takes different types, then it needs another name, except for generics, which are parameterized on type parameters.


## Variadic functions
Initially don't support it, but eventually we probably want params arguments, like in c#, which is just syntatctic sugar for creating an array and passing it in.

Although, we actually can do this without a memory allocation, if we use a special heap-allocated array, and then at the calling site, we don't expose the array itself, but rather expose some kind of iterable interface, like so:

void foo(int... args) {
	foreach (var arg in args) {
		// ...
	}
	// these are ok
	int len = varargs.length;
	int first = varargs[0];
	// error: type mismatch
	int[] foo = args;
	// error: unsupported type "int..."; varargs only allowed as input parameters
	int... bar = args;
	// allowed
	int[] foo = varargs.ToList();
	// also allowed (spread operator)
	foo(args...);
}

The good thing is this would be c-friendly. It could be implemented like:

Exception* foo(int argc, int[] argv);


## string formatting
First off, every type will get the "ToString" trait (whatever that should be called), which by default is like "full.TypeName[0xPOINTER]", but you can explicitly specify the ToString(string format) function.

Then, like in old c#, there will be some kind of a string.Format(string template, ToString... objects), which will act like c# I guess:
str = string.Format("Name: {0}, ID: {1:D10}", name.ToUpper(), id);

Then, maybe, we can have syntactic sugar for that, which looks like:
str = $"Name: {name.ToUpper()}, ID: {id:D10}";

Or, maybe not. I'm trying to reduce the features of the language, but it needs to be a nice balance.

Note that primitives (like id) will automatically be boxed. So, for example, `10.ToString(null)` will create a boxed temporary of 10, call ToString on it, and then leak it.


## default parameters
Hmm, maybe... could be nice? Could also be less explicit... or could cause confusion. Not for now, anyhow.


## finalizers
Yes, you can specify the finalizer in the class. This is mostly useful for freeing raw pointer memory. However, they should be very restricted. No touching other objects. No allocation. No resurrection. Any violation of this is undefined behavior.


## Polymorphism
No inheritance. However, you can specify traits, and when passing traits to things, it will pass a fat pointer.


## stack unwinding
Use backtrace() or libunwind on posix (and whatever windows provides). Then, you can use that when printing or dumping stack traces. If possible, try to unmangle function names.


## multiple return values
In crimp, every function will have 0 or more return values. This is unlike c, where everything has a single return value.

One thing that helps this design pattern is that all return values are facilitated by out parameters. So, 0 return values means 0 out parameters.

That means assignment statements need to support multiple assignment. This also means that calling a function and chaining its return value into the current expression is an exception rather than the rule in crimp:

Let's take a look at this:

foo();
bar() int;
baz() double, double;

foo() + 10; // error, because foo doesn't return any value
bar() + 20; // good
baz() + 3.33; // bad, because baz returns 2 values
var x: double;
x, var y: double = baz(); // good


## fast failure in c

If you want to call a bunch of functions, and want the application to die if any of them errors, you might do something like this:

foo(bar) || die();

Because they return a 0 pointer on success. However... on failure, we don't get the exception, which is awful. We might have to do something like:
unwrap(  foo(bar)  );

Which will do something like this:

Exception* _temp5384 = foo(bar);
if (_temp5384 != NULL) {
    die(_tmp5384);
}

Which would print the stack trace and any info in the exception itself, and then exit. It would also give the site of the error, so someone can easily investigate further.

So maybe we'd have unwrap(), for prototyping, and wont_throw(), for production code where you're pretty sure it won't actually throw (cross fingers).


## Exceptions
I think exceptions would need an inheritance hierarchy... I'll need to think about this. At the very least, the base exception will have a stacktrace, a specific file and line number, and a message.


## RTTI
The language will have RTTI, that it uses for everything. So, it's mandatory in classes. All class objects will have a reference to their type structure, which will have information such as name, some kind of dictionary structure of all implemented traits (so arbitrary objects can be cast to a trait at runtime), memory layout information. Type information will be exposed to users.

RTTI can be used to implement things like json encoding and decoding, ORM, etc, albeit more slowly than in languages that support compile-time execution, compile-time templating, or run-time compilation. I think it's a reasonable tradeoff anyhow.


## Generics
I had a big, long writeup on generics, but I changed my mind on it. Instead, let's handle generics the way c# does:

Monomorphize as little as possible. When it's defined, the dynamic specialization is always monomorphized, but other specializations are only created for value types.

The way it's implemented from a compilation-standpoint, is that every monomorphization of every generic that's required in a particular module is noted, and then it will create a monomorphizations_partial.o file of just the monomorphizations which haven't already been provided by other modules it depends on. Then, when the application is being built, it will link all the monomorphizations_partial.o object files together into a single dynamic library, which is used by all modules.

This is possible because of the observation that crimp code always ultimately results in the compilation of a crimp executable. Crimp libraries cannot be used as-is because of their crimp runtime dependency.

Note that all the monomorphizations are marked as "inline" functions, to allow for multiple sibling modules to have duplicate monomorphizations without causing a duplicate symbol error during linking.

This delta compilation of monomorphizations should reduce the amount of compilation required per compilation.


## Arrays
Default arrays will have their length embedded in the object (like in c#). I don't know if default arrays will be a special case in the language, or if they'll be a generic type. They should probably be a special case if there's any justification for it, but generics can handle them reasonably well.

There will be some kind of a "list" type which is a generic that wraps around an array. Strings will be a special case, I think, which will be immutable arrays of bytes (utf-8), and always 0-terminated. String builders will work like in c#.

I like the idea of a buffer type, which will be written to incrementally, and then can either be read back into another buffer type, or into a fixed-sized array (c buffer).

I also like another idea of a buffer writer type, which buffers for another writer type, and will flush either on the buffer being full, or on explicit flush.


## variable-length types
I'm thinking that variable-length types will work through overriding the allocation function, which will then allow you to allocate with a custom size. Then, it's up to you to handle data access. Have an example:

struct ArrayImpl {
	_header: TypeHeader; // this is crucial
	length: int; // should be const, but we assign to it during object creation, so easier this way
	data: []void;
}

class Array[T] {
	length: const int;
	// note: data is not exposed through the class, only the impl
	
	// so I guess, _call is a special keyword so you can do:
	// Type() instead of Type._call() (although the latter would still be valid)
	// Another thing to figure out: if we make constructors like this, then that means that we'll need some special logic around const...........
	unsafe fn _call(length: int) Array[T] {
		var impl: *void = allocBySize(sizeof(ArrayImpl) + sizeof(T)*length);
		impl->_header = getTypeHeader[Array[T]]();
		impl->length = length;
		var this = castPtrToClass[Array[T]](impl); // maybe there will be some logic around this?

		// this logic isn't necessary, because alloc is guaranteed to 0-initialize memory, which is what this logic also does
		for var i = 0; i < length; i = i+1 {
			this.set(i, T.default);
		}
		
		return this;
	}
	
	unsafe mth _getArrayImpl() *ArrayImpl {
		return *ArrayImpl(get_ptr(this)); // or whatever syntax we use to cast a class to a pointer
	}
	
	// in reality, get and set would be operator overloads for []. Possibly implemented through traits
	unsafe mth get(ix: int) T {
		if int < 0 || >= length {
			throw new IndexOutOfRangeException();
		}
		
		var arrayImpl = _getArrayImpl();
		var dataPtr = *T(&arrayImpl->data);
		return dataPtr[ix};
	}
	
	unsafe mth set(ix: int, val: T) {
		// ...
	}
}

Basically, variable-length types should be very rare, so let's just give full flexibility on how you wish to accomplish it.


## constructors
I guess all constructors should be named constructors. If you want a default constructor, name it something like "_call", which will allow for syntactic sugar for call syntax on the class. Behind the scenes, constructors will be functions which will first allocate data based on the size of the class, and then set it to "this", and allow you to modify const values on "this". Otherwise, you can perform construction yourself by allocating memory, 


## inline functions
I had a big writeup on inline functions, but really, it should work like this:

If the compiler thinks a function will be short enough to be worth inlining, it'll provide the source in addition to exposing a concrete function. Then, when the programmer uses the function, the compiler will try to inline it if it thinks it's worth it.


## compiler implementation
initially, the compiler will be written in c#, and will read crimp files and output c files. Once that has sufficient basic functionality, then a standard library will be developed, and a self-hosting compiler (using the same paradigm) will be implemented.


## fat pointers
For polymorphism, we'll pass fat pointers everywhere with [object pointer, trait vtable]. This is because looking up a vtable for a type is relatively expensive, but if you already have the vtable, then 

Fat pointers will be a structure type that looks like:

struct TraitName {
	void* ptr;
	TraitName_vtable* vt;
};

and then the vtables will look like:

struct TraitName_vtable {
	fp_1* fp_1;
	fp_2* fp_2;
	// ...
};

then traitHandles will look like:

then c code will use it like:

Hashable_tHBuilder* h_b = Hashable_tHBuilder_create();
unwrap(  get_hashable(&h_b->slot)  );
Hashable_tHandle* h = Hashable_tHBuilder_finish(h_b);
int hash
unwrap(  h->data.vt->getHash(h->data.ptr, &hash)  );
unwrap(  takes_hashable(h->data)  );
Hashable_tHandle_release(h);


## traits
Classes, structs, and primitives can all have traits. Boxed and unboxed versions of the same primitives have the same trait behavior. However, pointers to structs don't have that trait behavior (pointers have their own traits).

Let's handle traits, not the way rust handles traits, but the way c# handles interfaces. Then, when using trait-implemented logic, it must be accessed explicitly:

// note: Foo implements TBar, and TBar specifies baz(int)
Foo f = ...;
TBar(f).baz(10);
// this is an error
f.baz(10);

Hmm, I kinda like that casting syntax.

Ok, whenever using a generic trait, you always have to be explicit with type parameters:

// note: Foo implement TQuux[int], and TQuux[T] specifies asdf(int)
Foo f = ...;
TQuux[int](f).asdf(20);
// this is an error, because no type parameter is specified:
TQuux(f).asdf(20);


## operator overloading
Maybe we should support this at some point, but for now, it's out of scope. Honestly, it's probably a good idea......... Probably can handle it with traits.


## c helper functions
The language itself - but more importantly - the libraries will provide c helper functions. These functions will be native c functions callable from c, and the entire point of them is that they make your life way easier when working in c. For example:

crimp_String_handle* crimp_String_fromCstr("hello, world!");


## macros
Especially things like the __FILE__, __LINE__, __func__ macros. I dunno, but I kinda don't want anything other than basic conditional compilation (a la c#).


## pluggable backends
I think it makes sense to use a plug-in backend architecture. Then users can write their own backends - for example, if they want integration with, say, zig. Not super important, but it just makes sense anyhow.


## not pluggable gc
It would nice for the gc to be pluggable, to allow integration with other systems which use other GCs, but this just is not feasible. This is because the language paradigms are tightly integrated with the way the GC works. The only thing I can do, is once I have a stable API, I can try a few different implementations, but I'm fairly limited on the approaches I can use.